{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Collection & Integration:**\n",
        "\n",
        "*   Identify & access three datasets:\n",
        "\n",
        "  *   Traffic Dataset\n",
        "  *   Weather Dataset(inlcude temperature, precipitation, humidity & wind speed)\n",
        "  *   Event Dataset(Holidays/any events)\n",
        "\n",
        "\n",
        "*   Integrating Datasets from various sources into single dataset:\n",
        "\n",
        "  *   Data Syncronization by timestamp to match traffic with its weather and event info.\n",
        "  *   Developing a data integration pipeline to merge traffic, weather, and event data into a unified dataset.\n",
        "\n",
        "\n",
        "\n",
        "*   Handling data quality issues:\n",
        "\n",
        "  *   Cleaning the dataset (drop duplicates, fill/remove missing values, and fix inconsistencies)\n",
        "  *   Scaling variables to a common range.(Normalize or standardize)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7YTOZf606ec5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sCyIInpF6b1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries & loading all three datasets\n",
        "\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the traffic data\n",
        "traffic_data = pd.read_csv('Dataset_Uber Traffic.csv')\n",
        "traffic_data['DateTime'] = pd.to_datetime(traffic_data['DateTime'])\n",
        "\n",
        "# Load the weather data\n",
        "weather_data = pd.read_csv('weather.csv')\n",
        "weather_data['DateTime'] = pd.to_datetime(weather_data['date_time'])\n",
        "\n",
        "# Load the event data\n",
        "event_data = pd.read_csv('events.csv')\n",
        "\n",
        "# Convert 'date' to 'DateTime'\n",
        "event_data['DateTime'] = pd.to_datetime(event_data['date'])"
      ],
      "metadata": {
        "id": "jHIE5NVb6coJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Syncronization by timestamp to match traffic with its weather and event info.**"
      ],
      "metadata": {
        "id": "BUCvuzw1_aMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the year from the traffic data to align with\n",
        "traffic_year = traffic_data['DateTime'].dt.year.unique()[0]\n",
        "\n",
        "def adjust_year(df, target_year):\n",
        "    def replace_year(x):\n",
        "        try:\n",
        "            return x.replace(year=target_year)\n",
        "        except ValueError:\n",
        "            # Handle the February 29 case for leap years\n",
        "            if x.month == 2 and x.day == 29:\n",
        "                return x.replace(month=2, day=28, year=target_year)\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    df['DateTime'] = df['DateTime'].apply(replace_year)\n",
        "    return df\n",
        "\n",
        "# Adjust the year in weather data\n",
        "weather_data = adjust_year(weather_data, traffic_year)\n",
        "\n",
        "# Adjust the year in event data\n",
        "event_data = adjust_year(event_data, traffic_year)"
      ],
      "metadata": {
        "id": "7sSug3IA_2OJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Integration**\n",
        "Integrating all three datasets into a single dataset"
      ],
      "metadata": {
        "id": "Q5cauKfr6dSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the datasets on DateTime\n",
        "integrated_data = pd.merge(traffic_data, weather_data, on='DateTime', how='left')\n",
        "integrated_data = pd.merge(integrated_data, event_data, on='DateTime', how='left')"
      ],
      "metadata": {
        "id": "q168KLr_AIIm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handling Data quality issues:**"
      ],
      "metadata": {
        "id": "6QVh1110AhBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates\n",
        "integrated_data = integrated_data.drop_duplicates()\n",
        "\n",
        "# Handle missing values\n",
        "integrated_data = integrated_data.fillna(method='ffill')  # Example: forward fill"
      ],
      "metadata": {
        "id": "K2t30q8dAl8h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking columns in the integrated dataset\n",
        "print(integrated_data.columns)"
      ],
      "metadata": {
        "id": "oC7eoQynGM4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850705ed-7594-4a3b-ffa0-213ff1b07183"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['DateTime', 'Junction', 'Vehicles', 'ID', 'date_time', 'maxtempC',\n",
            "       'mintempC', 'totalSnow_cm', 'sunHour', 'uvIndex', 'uvIndex.1',\n",
            "       'moon_illumination', 'moonrise', 'moonset', 'sunrise', 'sunset',\n",
            "       'DewPointC', 'FeelsLikeC', 'HeatIndexC', 'WindChillC', 'WindGustKmph',\n",
            "       'cloudcover', 'humidity', 'precipMM', 'pressure', 'tempC', 'visibility',\n",
            "       'winddirDegree', 'windspeedKmph', 'date', 'day', 'holiday',\n",
            "       'holiday_type'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalization**"
      ],
      "metadata": {
        "id": "7ufA66lIGYsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize the relevant columns\n",
        "scaler = StandardScaler()\n",
        "integrated_data[['tempC', 'humidity', 'windspeedKmph']] = scaler.fit_transform(integrated_data[['tempC', 'humidity', 'windspeedKmph']])\n",
        "\n",
        "# Save the cleaned and merged data\n",
        "integrated_data.to_csv('integrated_data.csv', index=False)"
      ],
      "metadata": {
        "id": "L27ANQoIGd5m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the first 10 rows of combined dataset after normalization\n",
        "print(integrated_data.head(10))"
      ],
      "metadata": {
        "id": "H5NVHFQaGhsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d6fb19-0fcf-4c91-a5cd-d961e1793b61"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    DateTime  Junction  Vehicles           ID            date_time  maxtempC  \\\n",
            "0 2015-01-11         1        15  20151101001  2009-01-11 00:00:00      27.0   \n",
            "1 2015-01-11         1        15  20151101001  2010-01-11 00:00:00      26.0   \n",
            "2 2015-01-11         1        15  20151101001  2011-01-11 00:00:00      28.0   \n",
            "3 2015-01-11         1        15  20151101001  2012-01-11 00:00:00      29.0   \n",
            "4 2015-01-11         1        15  20151101001  2013-01-11 00:00:00      29.0   \n",
            "5 2015-01-11         1        15  20151101001  2014-01-11 00:00:00      28.0   \n",
            "6 2015-01-11         1        15  20151101001  2015-01-11 00:00:00      26.0   \n",
            "7 2015-01-11         1        15  20151101001  2016-01-11 00:00:00      27.0   \n",
            "8 2015-01-11         1        15  20151101001  2017-01-11 00:00:00      26.0   \n",
            "9 2015-01-11         1        15  20151101001  2018-01-11 00:00:00      27.0   \n",
            "\n",
            "   mintempC  totalSnow_cm  sunHour  uvIndex  ...  precipMM  pressure  \\\n",
            "0      15.0           0.0     11.6      6.0  ...       0.0    1016.0   \n",
            "1      17.0           0.0     11.6      5.0  ...       0.0    1015.0   \n",
            "2      14.0           0.0     11.6      5.0  ...       0.0    1012.0   \n",
            "3      17.0           0.0     11.6      5.0  ...       0.0    1014.0   \n",
            "4      16.0           0.0     11.6      6.0  ...       0.0    1014.0   \n",
            "5      15.0           0.0     11.6      6.0  ...       0.0    1014.0   \n",
            "6      12.0           0.0     11.6      5.0  ...       0.0    1017.0   \n",
            "7      14.0           0.0     11.6      5.0  ...       0.0    1017.0   \n",
            "8      16.0           0.0     10.2      6.0  ...       0.0    1013.0   \n",
            "9      18.0           0.0     11.6      6.0  ...       0.0    1016.0   \n",
            "\n",
            "      tempC visibility winddirDegree windspeedKmph  date  day  holiday  \\\n",
            "0 -1.250127       10.0         100.0     -0.654230   NaN  NaN      NaN   \n",
            "1 -0.637934        2.0         130.0     -1.136464   NaN  NaN      NaN   \n",
            "2 -1.862320       10.0          32.0     -0.895347   NaN  NaN      NaN   \n",
            "3 -0.637934       10.0         193.0     -1.859814   NaN  NaN      NaN   \n",
            "4 -1.250127       10.0          93.0     -0.171996   NaN  NaN      NaN   \n",
            "5 -1.556224       10.0         108.0     -0.413113   NaN  NaN      NaN   \n",
            "6 -2.474513       10.0          53.0     -0.654230   NaN  NaN      NaN   \n",
            "7 -1.862320       10.0          95.0     -0.413113   NaN  NaN      NaN   \n",
            "8 -1.250127       10.0          83.0     -1.136464   NaN  NaN      NaN   \n",
            "9 -0.944031       10.0         101.0     -0.895347   NaN  NaN      NaN   \n",
            "\n",
            "   holiday_type  \n",
            "0           NaN  \n",
            "1           NaN  \n",
            "2           NaN  \n",
            "3           NaN  \n",
            "4           NaN  \n",
            "5           NaN  \n",
            "6           NaN  \n",
            "7           NaN  \n",
            "8           NaN  \n",
            "9           NaN  \n",
            "\n",
            "[10 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   **Finally the data is now fully integrated, cleaned, and scaled, we have a reliable, unified dataset that captures traffic patterns alongside weather and event influences setting the stage for accurate exploration, insightful visualizations, and highâ€‘performance predictive models.**"
      ],
      "metadata": {
        "id": "1wY9Ls0fJe1X"
      }
    }
  ]
}